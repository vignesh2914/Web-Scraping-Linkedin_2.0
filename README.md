# Latest updation On scraping 2-2-24

Kindly read the Note file below atlast

# updates 1 
At this point, the scraper retrieves the data quickly .we added some new features likeÂ you can choose the filtering process on jobs based on the last 24 hours, the previous week, the previous month, etc. 

# updates 2
Add on like this: when using this way of scraping, it encounters error 429, which indicates that the server has stopped the http request for that website (too many requests). In order to fix that, we implemented various conditions, such as waiting 60 seconds after an error occurs before retrieving the data from the web and saving it in a CSV file.

# updates 3
Every time we execute our code, the saving as CSV file will now be done automatically and will have a new name. To accomplish this, update the filename with the current date and time.

if ur using vs code add this extention edit csv for better view to data 

If u want u can compare the demo file with main file and u can look the diffrence in the code 

Still not over this project

HAPPY CODING HAVE FUN BY scraping !!!!!!!!!!!!!!!!!!!!!!!!!!!!

Coming really soon ..........with exiting updates !!!!!!!!!!!!!!!!!!


# NOTE - Simple and easy version

Hi all this is an updated and simple version of webscraping my previous version was using selinium that was working good but it was bit complicated process

# ------------In this version u can fetch------------------

---->job title
---->location
---->role
---->link

Into an CSV file That will be saved in ur respective folder where do u done the code

HAPPY CODING HAVE FUN BY scraping !!!!!!!!!!!!!!!!!!!!!!!!!!!!
